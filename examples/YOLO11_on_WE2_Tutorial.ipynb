{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO11 Tutorial",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freddy4212/YOLO11_on_WE2/blob/main/examples/YOLO11_on_WE2_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a64e5e-7fb6-4574-967f-ee04684a7db4"
      },
      "source": [
        "!git clone https://github.com/kris-himax/ultralytics\n",
        "%cd ultralytics\n",
        "%pip install .\n",
        "%cd ..\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.53 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 42.1/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.a export original yolo11n int8 tflite with BatchMatMul Operater"
      ],
      "metadata": {
        "id": "TzDBo0EKhI-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=yolo11n.pt format=tflite int8=True no_post=False imgsz=192"
      ],
      "metadata": {
        "id": "nBU9kqcwnG4u",
        "outputId": "409f77b0-10c1-469f-b659-82a459451eb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 101MB/s]\n",
            "Ultralytics 8.3.53 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "WARNING âš ï¸ INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 192, 192) BCHW and output shape(s) (1, 84, 756) (5.4 MB)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753161109.356758    2809 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753161109.426058    2809 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'onnx>=1.12.0', 'onnx2tf>1.17.5,<=1.22.3', 'onnxslim>=0.1.31', 'tflite_support', 'onnxruntime'] not found, attempting AutoUpdate...\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.14.0 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting sng4onnx>=1.0.1\n",
            "  Downloading sng4onnx-1.0.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting onnx_graphsurgeon>=0.3.26\n",
            "  Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting onnx2tf<=1.22.3,>1.17.5\n",
            "  Downloading onnx2tf-1.22.3-py3-none-any.whl.metadata (136 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 136.6/136.6 kB 7.8 MB/s eta 0:00:00\n",
            "Collecting onnxslim>=0.1.31\n",
            "  Downloading onnxslim-0.1.61-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting tflite_support\n",
            "  Downloading tflite_support-0.4.4-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnx_graphsurgeon>=0.3.26) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (4.14.1)\n",
            "Collecting sympy>=1.13.3 (from onnxslim>=0.1.31)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxslim>=0.1.31) (25.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tflite_support) (1.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tflite_support) (25.2.10)\n",
            "INFO: pip is looking at multiple versions of tflite-support to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting onnxslim>=0.1.31\n",
            "  Downloading onnxslim-0.1.60-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting protobuf>=3.20.2 (from onnx>=1.12.0)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from tflite_support)\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pybind11>=2.6.0 (from tflite_support)\n",
            "  Downloading pybind11-3.0.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->tflite_support) (1.17.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->onnxslim>=0.1.31) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support) (2.22)\n",
            "Downloading sng4onnx-1.0.4-py3-none-any.whl (5.9 kB)\n",
            "Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl (57 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 57.9/57.9 kB 249.9 MB/s eta 0:00:00\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 16.0/16.0 MB 143.0 MB/s eta 0:00:00\n",
            "Downloading tflite_support-0.4.4-cp311-cp311-manylinux2014_x86_64.whl (60.8 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 60.8/60.8 MB 80.0 MB/s eta 0:00:00\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 162.1/162.1 kB 170.4 MB/s eta 0:00:00\n",
            "Downloading onnx2tf-1.22.3-py3-none-any.whl (435 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 435.0/435.0 kB 239.5 MB/s eta 0:00:00\n",
            "Downloading onnxslim-0.1.61-py3-none-any.whl (157 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 157.2/157.2 kB 134.9 MB/s eta 0:00:00\n",
            "Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 16.5/16.5 MB 173.7 MB/s eta 0:00:00\n",
            "Downloading pybind11-3.0.0-py3-none-any.whl (292 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 292.1/292.1 kB 232.1 MB/s eta 0:00:00\n",
            "Downloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.3/6.3 MB 172.1 MB/s eta 0:00:00\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 46.0/46.0 kB 188.2 MB/s eta 0:00:00\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 86.8/86.8 kB 242.3 MB/s eta 0:00:00\n",
            "Installing collected packages: sympy, sng4onnx, pybind11, protobuf, onnx2tf, humanfriendly, sounddevice, onnx, coloredlogs, tflite_support, onnxslim, onnxruntime, onnx_graphsurgeon\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnx2tf-1.22.3 onnx_graphsurgeon-0.5.8 onnxruntime-1.22.1 onnxslim-0.1.61 protobuf-3.20.3 pybind11-3.0.0 sng4onnx-1.0.4 sounddevice-0.5.2 sympy-1.14.0 tflite_support-0.4.4\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 28.9s, installed 7 packages: ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'onnx>=1.12.0', 'onnx2tf>1.17.5,<=1.22.3', 'onnxslim>=0.1.31', 'tflite_support', 'onnxruntime']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n",
            "100% 1.11M/1.11M [00:00<00:00, 25.8MB/s]\n",
            "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100% 1/1 [00:00<00:00, 53.34file/s]\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.4s, saved as 'yolo11n.onnx' (10.1 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=coco8.yaml'\n",
            "\n",
            "Dataset 'coco8.yaml' images not found âš ï¸, missing path '/content/datasets/coco8/images/val'\n",
            "Downloading https://ultralytics.com/assets/coco8.zip to '/content/datasets/coco8.zip'...\n",
            "100% 433k/433k [00:00<00:00, 15.1MB/s]\n",
            "Unzipping /content/datasets/coco8.zip to /content/datasets/coco8...: 100% 25/25 [00:00<00:00, 5102.56file/s]\n",
            "Dataset download success âœ… (0.6s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 22.4MB/s]\n",
            "Scanning /content/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<00:00, 119.84it/s]\n",
            "New cache created: /content/datasets/coco8/labels/val.cache\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m WARNING âš ï¸ >300 images recommended for INT8 calibration, found 4 images.\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.22.3...\n",
            "I0000 00:00:1753161175.774891    2809 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1753161175.775085    2809 single_machine.cc:361] Starting new session\n",
            "W0000 00:00:1753161176.717352    2809 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1753161176.717394    2809 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "I0000 00:00:1753161177.734388    2809 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "I0000 00:00:1753161177.734542    2809 single_machine.cc:361] Starting new session\n",
            "W0000 00:00:1753161178.622020    2809 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1753161178.622056    2809 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "I0000 00:00:1753161179.641655    2809 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "I0000 00:00:1753161179.641807    2809 single_machine.cc:361] Starting new session\n",
            "W0000 00:00:1753161180.515457    2809 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1753161180.515492    2809 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "W0000 00:00:1753161184.878681    2809 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1753161184.878716    2809 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "I0000 00:00:1753161184.959023    2809 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
            "W0000 00:00:1753161189.444992    2809 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1753161189.445027    2809 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
            "W0000 00:00:1753161193.219436    2809 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1753161193.219472    2809 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "W0000 00:00:1753161196.367147    2809 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1753161196.367179    2809 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 92.3s, saved as 'yolo11n_saved_model' (35.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as 'yolo11n_saved_model/yolo11n_int8.tflite' (2.7 MB)\n",
            "\n",
            "Export complete (94.1s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n_saved_model/yolo11n_int8.tflite imgsz=192 int8 \n",
            "Validate:        yolo val task=detect model=yolo11n_saved_model/yolo11n_int8.tflite imgsz=192 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml int8 \n",
            "Visualize:       https://netron.app\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.b export yolo11n int8 tflite with BatchMatMul Operater without post-proccessing"
      ],
      "metadata": {
        "id": "-jB1cqRjpVAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=yolo11n.pt format=tflite int8=True no_post=True imgsz=224"
      ],
      "metadata": {
        "id": "6345LhHooJ-O",
        "outputId": "d8aea2b0-babd-4e47-ad04-f0c8b6d0f585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.53 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "WARNING âš ï¸ INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) ((1, 144, 28, 28), (1, 144, 14, 14), (1, 144, 7, 7)) (5.4 MB)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740361987.266919    3530 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740361987.274301    3530 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 3.6s, saved as 'yolo11n.onnx' (10.1 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=coco8.yaml'\n",
            "Scanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m WARNING âš ï¸ >300 images recommended for INT8 calibration, found 4 images.\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.22.3...\n",
            "I0000 00:00:1740362034.835670    3530 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1740362034.835925    3530 single_machine.cc:361] Starting new session\n",
            "W0000 00:00:1740362037.478013    3530 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1740362037.478068    3530 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "I0000 00:00:1740362039.218658    3530 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "I0000 00:00:1740362039.218831    3530 single_machine.cc:361] Starting new session\n",
            "W0000 00:00:1740362042.148628    3530 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1740362042.148668    3530 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "I0000 00:00:1740362044.188200    3530 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "I0000 00:00:1740362044.188369    3530 single_machine.cc:361] Starting new session\n",
            "W0000 00:00:1740362047.123761    3530 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1740362047.123800    3530 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "W0000 00:00:1740362071.205808    3530 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1740362071.205843    3530 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "I0000 00:00:1740362071.269924    3530 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
            "W0000 00:00:1740362083.985777    3530 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1740362083.985812    3530 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
            "W0000 00:00:1740362096.728562    3530 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1740362096.728613    3530 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "W0000 00:00:1740362109.235289    3530 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1740362109.235323    3530 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 125.6s, saved as 'yolo11n_saved_model' (34.9 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as 'yolo11n_saved_model/yolo11n_int8.tflite' (2.6 MB)\n",
            "\n",
            "Export complete (126.0s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n_saved_model/yolo11n_int8.tflite imgsz=224 int8 \n",
            "Validate:        yolo val task=detect model=yolo11n_saved_model/yolo11n_int8.tflite imgsz=224 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml int8 \n",
            "Visualize:       https://netron.app\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.1 install vela compiler"
      ],
      "metadata": {
        "id": "KKVN-qJiiS5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ethos-u-vela\n",
        "!wget https://raw.githubusercontent.com/HimaxWiseEyePlus/ML_FVP_EVALUATION/main/vela/himax_vela.ini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTF2oMJdiCzT",
        "outputId": "4f41653d-f5eb-40b9-adc1-2f4c16d7379b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ethos-u-vela\n",
            "  Downloading ethos_u_vela-4.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting flatbuffers==24.3.25 (from ethos-u-vela)\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ethos-u-vela) (2.0.2)\n",
            "Requirement already satisfied: lxml>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from ethos-u-vela) (5.4.0)\n",
            "Downloading ethos_u_vela-4.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Installing collected packages: flatbuffers, ethos-u-vela\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "Successfully installed ethos-u-vela-4.3.0 flatbuffers-24.3.25\n",
            "--2025-07-22 05:14:36--  https://raw.githubusercontent.com/HimaxWiseEyePlus/ML_FVP_EVALUATION/main/vela/himax_vela.ini\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 889 [text/plain]\n",
            "Saving to: â€˜himax_vela.iniâ€™\n",
            "\n",
            "himax_vela.ini      100%[===================>]     889  --.-KB/s    in 0s      \n",
            "\n",
            "2025-07-22 05:14:37 (51.7 MB/s) - â€˜himax_vela.iniâ€™ saved [889/889]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.2 convert yolo11 int8 tflite to vela model"
      ],
      "metadata": {
        "id": "31jShpaSijwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!vela --accelerator-config ethos-u55-64 --config himax_vela.ini --system-config My_Sys_Cfg --memory-mode My_Mem_Mode_Parent --output-dir ./ ./yolo11n_saved_model/yolo11n_full_integer_quant.tflite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXp_JXYIijKz",
        "outputId": "8a935ce7-dcdc-4484-ece1-dd6096e2b88d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: TRANSPOSE 'model_30/tf.compat.v1.transpose_39/transpose;model_30/tf.compat.v1.transpose_38/transpose/perm;model_30/tf.compat.v1.transpose_38/transpose;' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 4, 16, 756] and permutation is: [0 1 3 2]\n",
            "Warning: TRANSPOSE 'model_30/tf.compat.v1.transpose_21/transpose' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 24, 24, 144] and permutation is: [0 3 1 2]\n",
            "Warning: TRANSPOSE 'model_30/tf.compat.v1.transpose_18/transpose' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 128, 6, 6] and permutation is: [0 2 3 1]\n",
            "Info: BATCH_MATMUL 'model_30/tf.linalg.matmul_3/MatMul' is a CPU only op\n",
            "Warning: TRANSPOSE 'model_30/tf.compat.v1.transpose_3/transpose' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 6, 6, 256] and permutation is: [0 3 1 2]\n",
            "Warning: TRANSPOSE 'model_30/tf.compat.v1.transpose_13/transpose' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 2, 36, 36] and permutation is: [0 1 3 2]\n",
            "Info: BATCH_MATMUL 'model_30/tf.linalg.matmul_1/MatMul;model_30/tf.compat.v1.transpose_6/transpose' is a CPU only op\n",
            "Warning: TRANSPOSE 'model_30/tf.compat.v1.transpose_11/transpose' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 128, 6, 6] and permutation is: [0 2 3 1]\n",
            "Warning: TRANSPOSE 'model_30/tf.compat.v1.transpose_26/transpose' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 12, 12, 144] and permutation is: [0 3 1 2]\n",
            "Warning: TRANSPOSE 'model_30/tf.compat.v1.transpose_31/transpose' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 6, 6, 144] and permutation is: [0 3 1 2]\n",
            "\n",
            "Network summary for yolo11n_full_integer_quant\n",
            "Accelerator configuration                Ethos_U55_64\n",
            "System configuration                       My_Sys_Cfg\n",
            "Memory mode                        My_Mem_Mode_Parent\n",
            "Accelerator clock                                 400 MHz\n",
            "Design peak SRAM bandwidth                       2.98 GB/s\n",
            "Design peak Off-chip Flash bandwidth             0.05 GB/s\n",
            "\n",
            "Total SRAM used                               1051.31 KiB\n",
            "Total Off-chip Flash used                     1984.86 KiB\n",
            "\n",
            "CPU operators = 10 (1.5%)\n",
            "NPU operators = 656 (98.5%)\n",
            "\n",
            "Average SRAM bandwidth                           0.58 GB/s\n",
            "Input   SRAM bandwidth                          19.03 MB/batch\n",
            "Weight  SRAM bandwidth                           9.03 MB/batch\n",
            "Output  SRAM bandwidth                          11.27 MB/batch\n",
            "Total   SRAM bandwidth                          39.41 MB/batch\n",
            "Total   SRAM bandwidth            per input     39.41 MB/inference (batch size 1)\n",
            "\n",
            "Average Off-chip Flash bandwidth                 0.03 GB/s\n",
            "Input   Off-chip Flash bandwidth                 0.01 MB/batch\n",
            "Weight  Off-chip Flash bandwidth                 1.75 MB/batch\n",
            "Output  Off-chip Flash bandwidth                 0.00 MB/batch\n",
            "Total   Off-chip Flash bandwidth                 1.78 MB/batch\n",
            "Total   Off-chip Flash bandwidth  per input      1.78 MB/inference (batch size 1)\n",
            "\n",
            "Neural network macs                         293259600 MACs/batch\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Predict\n",
        "\n",
        "YOLO11 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32d4bcf-0fc9-4702-b537-8c60debd74c0"
      },
      "source": [
        "# Run inference on an image with YOLO11n\n",
        "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/zidane.jpg'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.53 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "Downloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n",
            "100% 49.2k/49.2k [00:00<00:00, 9.61MB/s]\n",
            "image 1/1 /content/zidane.jpg: 384x640 2 persons, 1 tie, 45.1ms\n",
            "Speed: 3.1ms preprocess, 45.1ms inference, 328.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzDWJ7cWTr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/212889447-69e5bdf1-5800-4e29-835e-2ed2336dede2.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Val\n",
        "Validate a model's accuracy on the [COCO](https://docs.ultralytics.com/datasets/detect/coco/) dataset's `val` or `test` splits. The latest YOLO11 [models](https://github.com/ultralytics/ultralytics#models) are downloaded automatically the first time they are used. See [YOLO11 Val Docs](https://docs.ultralytics.com/modes/val/) for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQPtK1QYVaD_",
        "outputId": "8b5b101e-6287-44f5-a7f3-6a02bff76af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download COCO val\n",
        "import torch\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d datasets && rm tmp.zip  # unzip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 780M/780M [00:08<00:00, 92.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH",
        "outputId": "2907303e-b3c5-4b07-b6d5-194664866f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Validate YOLO11n on COCO8 val\n",
        "!yolo val model=yolo11n.pt data=coco8.yaml"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.53 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.87s/it]\n",
            "                   all          4         17       0.57       0.85      0.847      0.632\n",
            "                person          3         10      0.557        0.6      0.585      0.272\n",
            "                   dog          1          1      0.548          1      0.995      0.697\n",
            "                 horse          1          2      0.531          1      0.995      0.674\n",
            "              elephant          1          2      0.371        0.5      0.516      0.256\n",
            "              umbrella          1          1      0.569          1      0.995      0.995\n",
            "          potted plant          1          1      0.847          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 28.5ms inference, 0.0ms loss, 58.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://ultralytics.com/hub\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png\"/></a></p>\n",
        "\n",
        "Train YOLO11 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO11 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLO11 ğŸš€ logger {run: 'auto'}\n",
        "logger = 'Comet' #@param ['Comet', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir ."
      ],
      "metadata": {
        "id": "ktegpM42AooT",
        "outputId": "7dc5ae50-f449-4444-ae6d-77f62a38f995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/728.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m727.0/728.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m728.6/728.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/3.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m145.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m comet_ml.init() is deprecated and will be removed soon. Please use comet_ml.login()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please paste your Comet API key from https://www.comet.com/api/my/settings/\n",
            "(api key may not show as you type)\n",
            "Comet API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "outputId": "ac5b497f-3a22-43d8-9a6a-f7b503fb65b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train YOLO11n on COCO8 for 3 epochs\n",
        "!yolo train model=yolo11n.pt data=coco8.yaml epochs=3 imgsz=640"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.168 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.53 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, no_post=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753162079.355481    7138 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753162079.361739    7138 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLO11n summary: 319 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/freddy4212/general/8bac89b3f0bf4681b884540259206965\u001b[0m\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<00:00, 1687.34it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco8/labels/train.cache\n",
            "/usr/local/lib/python3.11/dist-packages/ultralytics/data/augment.py:1850: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, p=0.0),\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/3      0.74G     0.9753      2.326      1.291         18        640: 100% 1/1 [00:01<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.81it/s]\n",
            "                   all          4         17      0.586       0.85      0.878      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/3     0.713G      1.299      3.249      1.677         22        640: 100% 1/1 [00:00<00:00,  6.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.67it/s]\n",
            "                   all          4         17      0.592       0.85      0.848       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/3     0.705G      1.419      3.156      1.469         27        640: 100% 1/1 [00:00<00:00,  7.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  9.61it/s]\n",
            "                   all          4         17       0.57       0.85       0.85      0.633\n",
            "\n",
            "3 epochs completed in 0.002 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.53 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 23.42it/s]\n",
            "                   all          4         17      0.586       0.85      0.878      0.634\n",
            "                person          3         10      0.572        0.6      0.593      0.267\n",
            "                   dog          1          1      0.552          1      0.995      0.697\n",
            "                 horse          1          2      0.599          1      0.995      0.674\n",
            "              elephant          1          2      0.368        0.5      0.695      0.275\n",
            "              umbrella          1          1      0.572          1      0.995      0.995\n",
            "          potted plant          1          1      0.853          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 4.4ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : defensive_antlion_4738\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : \u001b[38;5;39mhttps://www.comet.com/freddy4212/general/8bac89b3f0bf4681b884540259206965\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.84824, 0.87795)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.63027, 0.6338579205678042)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.57003, 0.5919)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B)        : 0.85\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 6.614\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2624080\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 41.755\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.97532, 1.41887)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (2.3256, 3.24852)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.29133, 1.67658)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.65088, 1.67569)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.01535, 1.02784)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.37625, 1.38614)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/coco8.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     no_post         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 13\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.28 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 2 (14.89 KB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 12 file(s), remaining 3.36 MB/8.62 MB\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Export\n",
        "\n",
        "Export a YOLO11 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLO11 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
        "\n",
        "- ğŸ’¡ ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n",
        "- ğŸ’¡ ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n",
        "\n",
        "| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n",
        "|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                          | -                 | `yolo11n.pt`              | âœ…        | -                                                                    |\n",
        "| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolo11n.torchscript`     | âœ…        | `imgsz`, `optimize`, `batch`                                         |\n",
        "| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolo11n.onnx`            | âœ…        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n",
        "| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolo11n_openvino_model/` | âœ…        | `imgsz`, `half`, `dynamic`, `int8`, `batch`                          |\n",
        "| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolo11n.engine`          | âœ…        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n",
        "| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolo11n.mlpackage`       | âœ…        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n",
        "| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolo11n_saved_model/`    | âœ…        | `imgsz`, `keras`, `int8`, `batch`                                    |\n",
        "| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolo11n.pb`              | âŒ        | `imgsz`, `batch`                                                     |\n",
        "| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolo11n.tflite`          | âœ…        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolo11n_edgetpu.tflite`  | âœ…        | `imgsz`                                                              |\n",
        "| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolo11n_web_model/`      | âœ…        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolo11n_paddle_model/`   | âœ…        | `imgsz`, `batch`                                                     |\n",
        "| [MNN](https://docs.ultralytics.com/integrations/mnn)                     | `mnn`             | `yolo11n.mnn`             | âœ…        | `imgsz`, `batch`, `int8`, `half`                                     |\n",
        "| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolo11n_ncnn_model/`     | âœ…        | `imgsz`, `half`, `batch`                                             |\n",
        "| [IMX500](https://docs.ultralytics.com/integrations/sony-imx500)          | `imx`             | `yolov8n_imx_model/`      | âœ…        | `imgsz`, `int8`                                                      |"
      ],
      "metadata": {
        "id": "nPZZeNrLCQG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=yolo11n.pt format=torchscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYIjW4igCjqD",
        "outputId": "737206e7-49f7-45ce-bf78-cbb9b0f64467"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.53 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.6.0+cu124...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 2.2s, saved as 'yolo11n.torchscript' (10.5 MB)\n",
            "\n",
            "Export complete (2.8s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n.torchscript imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n.torchscript imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Python Usage\n",
        "\n",
        "YOLO11 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLO11 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See detailed Python usage examples in the [YOLO11 Python Docs](https://docs.ultralytics.com/usage/python/)."
      ],
      "metadata": {
        "id": "kUMOQ0OeDBJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolo11n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolo11n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='coco8.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
        "results = model.export(format='onnx')  # export the model to ONNX format"
      ],
      "metadata": {
        "id": "bpF9-vS_DAaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Detection\n",
        "\n",
        "YOLO11 _detection_ models have no suffix and are the default YOLO11 models, i.e. `yolo11n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for full details.\n"
      ],
      "metadata": {
        "id": "yq26lwpYK1lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n, train it on COCO128 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n.pt')  # load a pretrained YOLO detection model\n",
        "model.train(data='coco8.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "8Go5qqS9LbC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pip install from source\n",
        "!pip install git+https://github.com/ultralytics/ultralytics@main"
      ],
      "metadata": {
        "id": "pIdE6i8C3LYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone and run tests on updates branch\n",
        "!git clone https://github.com/ultralytics/ultralytics -b main\n",
        "%pip install -qe ultralytics"
      ],
      "metadata": {
        "id": "uRKlwxSJdhd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tests (Git clone only)\n",
        "!pytest ultralytics/tests"
      ],
      "metadata": {
        "id": "GtPlh7mcCGZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate multiple models\n",
        "for x in 'nsmlx':\n",
        "  !yolo val model=yolo11{x}.pt data=coco.yaml"
      ],
      "metadata": {
        "id": "Wdc6t_bfzDDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}